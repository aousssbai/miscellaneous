{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a code I wrote at the very beginning of the project to try out a random forest classifier, and used it for some part of the testing and result generation, in complement to axureML predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3,4,5,6,7,8,9,10],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "train = pd.read_csv('training.csv')  \n",
    "test = pd.read_csv('testing.csv')\n",
    "Xtrain = train[featureList]\n",
    "Ytrain = train[\"UserName\"]\n",
    "\n",
    "grid_search.fit(Xtrain, Ytrain)\n",
    "grid_search.best_params_\n",
    "\n",
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = evaluate(best_grid, Xtest, Ytest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=80, max_features=6,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=3, min_samples_split=8,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "forest = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=80, max_features=6,\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=3, min_samples_split=8,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
    "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
    "                       warm_start=False)\n",
    "\n",
    "# This is the list of features you want to use for your log classification\n",
    "featureList = []\n",
    "\n",
    "# We set up the feature importance dictionary which will hold importance score of each feature in the claasification\n",
    "importanceDict = {}\n",
    "for feature in featureList: \n",
    "    importanceDict[feature] = 0\n",
    "\n",
    "metricsDict = {}\n",
    "metricsDict[\"precision\"] = 0 \n",
    "metricsDict[\"recall\"] = 0\n",
    "metricsDict[\"fscore\"] = 0\n",
    "\n",
    "#here you input the list of usernames you want to test  \n",
    "nameList = []\n",
    "for name in nameList:\n",
    "    #those are example files for PF logs. you simply need to input the path of the logs you want to use for training and testing\n",
    "    train = pd.read_csv('PF/'+name+'_pf_train.csv')  \n",
    "    test = pd.read_csv('PF/'+name+'_pf_predict.csv')\n",
    "\n",
    "    Xtrain = train[featureList]\n",
    "    Ytrain = train[\"user\"]\n",
    "    Xtest  = test[featureList]\n",
    "    Ytest  = test[\"user\"]\n",
    "\n",
    "    forest.fit(Xtrain, Ytrain)\n",
    "    Ypred = forest.predict(Xtest)\n",
    "    \n",
    "    metrics = precision_recall_fscore_support(Ytest, Ypred, average='macro')\n",
    "    metricsDict[\"precision\"] += metrics[0]\n",
    "    metricsDict[\"recall\"] += metrics[1]\n",
    "    metricsDict[\"fscore\"] += metrics[2]\n",
    "    \n",
    "\n",
    "    #FEATURE IMPORTANCE\n",
    "    importances = forest.feature_importances_\n",
    "    for i in range (0,len(importances)):\n",
    "        importanceDict[featureList[i]] += importances[i]\n",
    "        \n",
    "        \n",
    "for metric in metricsDict: \n",
    "    metricsDict[metric] = metricsDict[metric]/len(nameList)      \n",
    "        \n",
    "plt.bar(list(metricsDict.keys()), metricsDict.values(), color='r')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for feature in featureList: \n",
    "    importanceDict[feature] = importanceDict[feature]/len(nameList)\n",
    "importanceDict = {k: v for k, v in sorted(importanceDict.items(), key=lambda item: item[1], reverse=True)} \n",
    "\n",
    "plt.bar(list(importanceDict.keys()), importanceDict.values(), color='b')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
